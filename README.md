# YAML Multi-Agent Orchestration Engine

A declarative AI agent workflow system that enables you to define and execute multi-agent pipelines using simple YAML configuration files.

## ğŸ—ï¸ Architecture
```
USER / CLI
â”‚
â”‚  python run.py workflow.yaml --query "User Task"
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ORCHESTRATION ENGINE                     â”‚
â”‚                                                             â”‚
â”‚  â€¢ Parses YAML workflows                                    â”‚
â”‚  â€¢ Decides execution pattern                                â”‚
â”‚    (sequential / parallel / hierarchical)                   â”‚
â”‚  â€¢ Central controller for memory + tools                    â”‚
â”‚                                                             â”‚
â”‚  â†’ Agents NEVER talk directly                               â”‚
â”‚  â†’ Agents NEVER access memory directly                      â”‚
â”‚  â†’ Agents NEVER call tools directly                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                               â”‚
                â”‚                               â”‚
                â–¼                               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    AGENT A   â”‚               â”‚    AGENT B   â”‚
        â”‚ (Role+Goal)  â”‚               â”‚ (Role+Goal)  â”‚
        â”‚               â”‚               â”‚               â”‚
        â”‚ â€¢ Receives final prompt       â”‚ â€¢ Receives final prompt
        â”‚ â€¢ Executes LLM reasoning      â”‚ â€¢ Executes LLM reasoning
        â”‚ â€¢ Requests tools via orch.    â”‚ â€¢ Requests tools via orch.
        â”‚ â€¢ Returns output to orch.     â”‚ â€¢ Returns output to orch.
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                â”‚                               â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ORCHESTRATOR (CORE)                      â”‚
â”‚                                                             â”‚
â”‚  â€¢ Stores outputs in short-term workflow memory             â”‚
â”‚  â€¢ Creates embeddings for long-term memory                  â”‚
â”‚  â€¢ Injects shared context into next agents                  â”‚
â”‚                                                             â”‚
â”‚  Tool Flow:                                                  â”‚
â”‚   Agent â†’ Orchestrator â†’ MCP Server â†’ Orchestrator â†’ Agent  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  VECTOR DATABASE (ChromaDB)                 â”‚
â”‚                                                             â”‚
â”‚  â€¢ Long-term memory                                         â”‚
â”‚  â€¢ Semantic embeddings (meaning-based)                      â”‚
â”‚  â€¢ Cross-session learning                                   â”‚
â”‚                                                             â”‚
â”‚  Queried ONLY by orchestrator                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–²
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               SHORT-TERM WORKFLOW MEMORY                    â”‚
â”‚                                                             â”‚
â”‚  â€¢ In-memory (RAM)                                          â”‚
â”‚  â€¢ Lives for one execution                                  â”‚
â”‚  â€¢ Shared context across agents                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MCP SERVER                           â”‚
â”‚                                                             â”‚
â”‚  â€¢ Exposes tools via Model Context Protocol                  â”‚
â”‚  â€¢ API calls, DB queries, filesystem, etc                   â”‚
â”‚                                                             â”‚
â”‚  Accessed ONLY through Orchestrator                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
## ğŸš€ Quick Start

### 1. Setup Environment

```bash
# Clone and navigate to project
cd final-YAML-Project

# Install dependencies
pip install -r requirements.txt

# Set your API key (choose one)
echo 'GOOGLE_API_KEY=your-gemini-api-key' > .env
# OR
echo 'OPENAI_API_KEY=your-openai-api-key' > .env
```

### 2. Run a Workflow

```bash
# Basic execution
python3 run.py examples/sequential.yaml --query "Tell me about AI"

# Parallel workflow
python3 run.py examples/parallel.yaml --query "Design a todo app"
```

---

## ğŸ“Š Viewing Execution Logs

To see detailed logs of what happens during the generation process, use the `--verbose` flag:

```bash
python3 run.py examples/sequential.yaml --query "Tell me about AI" --verbose
```

### Sample Verbose Output

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Time                â”ƒ Event                     â”ƒ Agent      â”ƒ Details    â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ 2026-01-18T10:13:19 â”‚ vector_memory_initialized â”‚ -          â”‚            â”‚
â”‚ 2026-01-18T10:13:19 â”‚ orchestrator_initialized  â”‚ -          â”‚            â”‚
â”‚ 2026-01-18T10:13:19 â”‚ execution_start           â”‚ -          â”‚            â”‚
â”‚ 2026-01-18T10:13:19 â”‚ sequential_start          â”‚ -          â”‚            â”‚
â”‚ 2026-01-18T10:13:19 â”‚ step_start                â”‚ researcher â”‚            â”‚
â”‚ 2026-01-18T10:13:19 â”‚ agent_start               â”‚ researcher â”‚            â”‚
â”‚ 2026-01-18T10:13:31 â”‚ output_stored             â”‚ researcher â”‚ 9407 chars â”‚
â”‚ 2026-01-18T10:13:31 â”‚ facts_stored              â”‚ researcher â”‚            â”‚
â”‚ 2026-01-18T10:13:31 â”‚ agent_complete            â”‚ researcher â”‚ 9407 chars â”‚
â”‚ 2026-01-18T10:13:31 â”‚ step_complete             â”‚ researcher â”‚ 9407 chars â”‚
â”‚ 2026-01-18T10:13:31 â”‚ step_start                â”‚ writer     â”‚            â”‚
â”‚ 2026-01-18T10:13:31 â”‚ agent_start               â”‚ writer     â”‚            â”‚
â”‚ 2026-01-18T10:13:38 â”‚ output_stored             â”‚ writer     â”‚ 2828 chars â”‚
â”‚ 2026-01-18T10:13:39 â”‚ agent_complete            â”‚ writer     â”‚ 2828 chars â”‚
â”‚ 2026-01-18T10:13:39 â”‚ step_complete             â”‚ writer     â”‚ 2828 chars â”‚
â”‚ 2026-01-18T10:13:39 â”‚ sequential_complete       â”‚ -          â”‚            â”‚
â”‚ 2026-01-18T10:13:39 â”‚ execution_complete        â”‚ -          â”‚            â”‚
â”‚ 2026-01-18T10:13:39 â”‚ memory_saved              â”‚ -          â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Log Events Explained

| Event | Description |
|-------|-------------|
| `vector_memory_initialized` | Vector database for persistent memory is ready |
| `orchestrator_initialized` | Workflow engine is set up |
| `execution_start` | Workflow execution begins |
| `agent_start` | An agent starts processing |
| `output_stored` | Agent output saved to memory |
| `facts_stored` | Key facts extracted and stored |
| `agent_complete` | Agent finished processing |
| `execution_complete` | Entire workflow completed |
| `memory_saved` | All data persisted to disk |

---

## ğŸ“ Log Storage Locations

| Location | Description |
|----------|-------------|
| `memory/` | Workflow execution history and agent outputs |
| `vector_db/` | Semantic vector embeddings for persistent memory |

---

## ğŸ› ï¸ CLI Commands

```bash
# Run workflow
python3 run.py <yaml_file> --query "your query"

# Run with verbose logs
python3 run.py <yaml_file> --query "your query" --verbose

# Validate YAML only (no execution)
python3 run.py --validate <yaml_file>

# Start API server
python3 run.py --server
```

---

## ğŸ”‘ Supported Models

| Provider | Model | Environment Variable |
|----------|-------|---------------------|
| Google | gemini-2.5-flash | `GOOGLE_API_KEY` |
| OpenAI | gpt-4o | `OPENAI_API_KEY` |
| Anthropic | claude-sonnet-4-20250514 | `ANTHROPIC_API_KEY` |

---

## ğŸ“„ Example YAML Structure

```yaml
agents:
  - id: researcher
    role: Research Assistant
    model: gemini
    goal: Find key insights
    instruction: |
      Analyze the topic and provide findings.

  - id: writer
    role: Content Writer
    model: gemini
    goal: Write engaging content
    instruction: |
      Create a summary from the research.

workflow:
  type: sequential
  steps:
    - agent: researcher
    - agent: writer

models:
  gemini:
    provider: google
    model: gemini-2.5-flash
    max_tokens: 4096
    temperature: 0.7
```

---

## ğŸš€ MCP Tools Integration

To use MCP (Model Context Protocol) tools:

### Terminal 1: Start MCP Server
```bash
python3 mcp_server.py
```

### Terminal 2: Run Tool-Enabled Workflow
```bash
python3 run.py examples/submission/03_tool_enabled_data_analysis.yaml --query "Analyze Q4 sales data"
```
